Did:
1. Running large/A.txt and large/B.txt using src/matrix_multiply_cache_opt_tensor.cu
   works well.  Using output_cmp.py all the errors were within 7% difference compared
   to the 66.6% difference for the very_large/*.txt data. The 66.6% is b/c there 
   are 0's on rows ~6666->20000 of the output. 
2. Modified simpleTensorCoreGEMM_ali_adapted.cu to read data from file. Let's try 
   the cuBLAS.cu and see if it suffers from the same problems.
   

To Do:
1. Fix bug where not all the output is saved from wmma
